\section{Data and simulation}
\label{sec:htoinv_data_sim}

A summary of the datasets comprising \acrshort{cms} data, and simulated signal and background samples is given below.


%=========================================================


\subsection{Data}
\label{subsec:htoinv_data}

The data collected by the \acrshort{cms} experiment that is used in the analysis corresponds to an integrated luminosity of 137.2\fbinv, and recorded from 2016--2018. A breakdown by year is given in Tab.~\ref{tab:lumis_lhc_cms}. At over three times the volume at \comruntwo analysed in previous searches, there is potential to substantially lower the ceiling of $\BRof{\higgstoinv}$. Data is split into \emph{\glspl{PD}} that are grouped by the class of \acrshort{hlt} path that an event triggered. The signal region, \acrshort{qcd} \glspl{SB}, and muon \glspl{CR} use the \gls{PD} composed of \ptmiss and \htmiss combination triggers, where muons are excluded from the sums. The datasets made use of in the electron and photon \glspl{CR} consist of triggers based on the properties of those objects. These were separate for 2016 and 2017, then merged for 2018.

Some serious issues arose during Run-2 that had to be mitigated after the events were reconstructed. With the high collision rate at \acrshort{cms}, in order to properly correlate the hits in the subdetectors with the correct particles and events they are attributed to, the timing infrastructure must be very precise. Timing scans are conducted frequently during runs to correct or compensate for any shifts that may occur. However, in 2016 and 2017, the gradual timing drift in the \acrshort{ecal} was not correctly propagated to the \acrlong{l1} trigger primitives. This resulted in a significant fraction of them in the forward direction (as the effect increases with $\eta$) being mistakenly associated to the previous bunch crossing, known as \emph{pre-firing}. One rule at \acrlong{l1} forbids two consecutive bunch crossings from firing signals to the trigger system. But, a consequence of this---in addition to not finding the primitive in the nominal bunch crossing---is that events can be vetoed if a significant amount of \acrshort{ecal} energy is found in the $\text{2} < \abseta < \text{3}$ part of the end cap. It is observed only in data, and so a correction is applied to \acrshort{mc} (see Chpt.~\ref{subsec:htoinv_minor_weights_systs}) to account for the effect.

In 2018, a sector of the \acrshort{hcal} end cap lost power, leaving the approximate area bound by $\eta \in \text{[}\mkern-5mu - \mkern-5mu \text{3.0}, -\text{1.4]}$ and $\phi \in \text{[} \mkern-5mu - \mkern-5mu \text{1.57}, -\text{0.87]}$ inoperative for the remainder of the year. Of the 59.7\fbinv recorded and certified for use in 2018, 38.6\fbinv were affected. With this section missing, it was more difficult to accurately record the properties of \glspl{jet}, and therefore reliably calculate the \ptvecmiss. Studies performed showed an excess in data in the affected area of the $\phi(\ptvecmiss)$ distribution of most regions and categories. To mitigate this issue, the cuts in Chpt.~\ref{subsec:htoinv_hem_mitigation} were added to the preselection.


%=========================================================


\subsection{Simulated signal processes}
\label{subsec:htoinv_signal}

All \acrlong{mc} datasets in this analysis were produced centrally as outlined in Chpt.~\ref{subsec:cms_mc}. The signal samples are generated at \acrshort{nlo} with the \POWHEG generator interfaced with \PYTHIAEIGHT. When reweighting events for their cross section, they are specified at the highest accuracy available as given in Tab.~\ref{tab:htoinv_signal_xsecs}. The samples are produced with a Higgs boson mass of $m_{\PH} = \text{125}\GeV$ and assumes a 100\,\% branching ratio to invisible states. In each of the \VH channels, the vector boson decays to $\Pquark\APquark$. Simulation of the \ggH and \acrshort{vbf} processes are included as their high cross sections and somewhat similar topologies would lead to a degree of overlap with the \ttH-- and \VH--tagged events.

When simulating 2016 data, the tuning of the shower parameters in \PYTHIA was labelled \textsc{cuetp8m1}~\cite{Khachatryan:2015pea} (the standard at the time), whilst for 2017 and 2018 datasets was replaced by the newer \textsc{cp5} version~\cite{Sirunyan:2019dfx}.


%=========================================================


\subsection{Simulated background processes}
\label{subsec:htoinv_background}

\acrlong{mc} datasets for many processes are required in the analysis to accurately represent the \acrlong{sm} background. Every one uses \PYTHIAEIGHT to hadronise the events generated by the hard scatter. The underlying event tune applied in the hadroniser follows the same prescription as with signal---\textsc{cuetp8m1} for simulating 2016 while \textsc{cp5} is used thereafter. The only exception is the $\ttbarpjets$ background, for which \emph{all} samples were generated with the \textsc{cp5} tune. They are described as follows:

\begin{easylist}[itemize]
    \easylistprops
    & \ttbarpjets: The \acrshort{qcd}-induced process presents a major background, largely in the \ttH channel. Large \ptmiss can arise in lost lepton scenarios. The three channels (hadronic, semi-leptonic, and dileptonic) are modelled with \POWHEG at \acrshort{nlo} accuracy.

    & \ztonunupjets: From the presence of neutrinos, the genuine \ptvecmiss from this channel is a formidable background in the signal region. The datasets are generated at \acrshort{lo} accuracy with \MGvATNLO.

    & \wtolnupjets: A \acrshort{qcd}-induced process, this decay is dominant in the single lepton \glspl{CR}. If the lepton is lost, the \ptmiss can be be inflated and lead to a significant contribution in the signal region. The datasets are produced at \acrshort{lo} with \MGvATNLO.

    & \acrshort{qcd} multijet: The most common type of event produced in \pp collisions at the \acrshort{lhc} is several \glspl{jet} from \acrshort{qcd} vertices. These typically do not have large \ptmiss, but its high cross section leads to a significant number of events with mismeasured momenta that can artificially increase it. As such, they serve as a non-negligible background in the analysis. The datasets are produced at \acrshort{lo} by \MGvATNLO.

    & Multiboson: This process encompasses the production of two (diboson) or three (triboson) electroweak bosons. They may decay into charged leptons with or without neutrinos, but also hadronically---producing \glspl{jet}. A mixture of the two in an event will lead to similar signatures to that of the signal. The diboson processes are both generated and showered with \PYTHIAEIGHT at \acrshort{lo}. For triboson events, on the other hand, \MGvATNLO at \acrshort{nlo} accuracy models the hard scatter.

    & Electroweak $\PVec + \text{2 jets}$: The production of electroweak bosons from an electroweak vertex is a minor background in the signal region. But as above, they may produce genuine \ptmiss from the decay of the \PVec. The datasets are generated at \acrshort{lo} with \MGvATNLO.

    & Single top: Events with one final-state top quark are a subdominant background in the analysis, but are important to consider, especially in the \ttH channel. These electroweak-induced processes include \schannel and \tchannel production where a \emph{four-flavour scheme}~\cite{Krauss:2017wmx} in the event generator is used for treatment of \Pbottom quarks. This approach considers the \Pbottom as massive, and as such, may only enter the final state. Associated production with a \PW boson (known as $\Ptop\PW$) is also considered with a five-flavour scheme, i.e., \Pbottom quarks may be considered massless and can appear in both the initial and final states. For all of these channels, the events are produced at \acrshort{nlo}. Modelling the hard scatter for the \schannel diagram is performed with \MGvATNLO. The \tchannel and $\Ptop\PW$ mechanisms are generated with \POWHEG, with the former decaying the $\PW$ exchanged by the initial state $\Pbottom$ and $\Pquark$ with \MADSPIN~\cite{Artoisenet:2012st} to include spin correlations.

    & $\ttbar X \plusjets$: These are rare processes where a boson $X$ ($\Pphoton$, $\PW$, $\PZ$, $\PH$) is produced in association with a \ttbar pair. Several combinations of the decays of the \ttbar and $X$ are covered. All of the datasets are generated at \acrshort{nlo}. The $\ttbar \Pphoton \plusjets$ and $\ttbar \PW \plusjets$ datasets use \MGvATNLO, and decay the particles with \MADSPIN. $\ttbar \PZ \plusjets$ also uses \MGvATNLO but without the aforementioned addition. Meanwhile, $\ttH \plusjets$ (where the \PH decays to visible states) is generated with \POWHEG.

    & Drell-Yan $(\HepProcess{\PZ \to \Plepton\Plepton}) \plusjets$: The Drell-Yan process occurs when the quark of one incident proton annihilates with the antiquark in the oncoming proton, producing a neutral vector boson (a \PZ in this case) from a \acrshort{qcd} vertex. It subsequently decays to a lepton pair. So while absent in the signal region, it is dominant in the dilepton \glspl{CR} for modelling the \ztonunupjets process. The datasets are generated at \acrshort{lo} accuracy with \MGvATNLO, where a dilepton mass cut of 50\GeV is applied.

    & \gammapjets: Events with photons are vetoed in the signal region. However, this is the largest contributor to the \singlePhotonCr \gls{CR} that predicts---along with the dilepton \glspl{CR}---the \ztonunupjets contribution to the signal region. These datasets are generated at \acrshort{nlo} with \MGvATNLO in bins of $\pt^{\Pphoton}$.

\end{easylist}


%=========================================================


\subsection{Cross section reweighting}
\label{subsec:xs_weighting}

Cross sections are specified at the highest order available, except for the \acrshort{lo} $\PVec \plusjets$ processes that require reweighting, expounded in Chpt.~\ref{subsec:htoinv_nlo_corrs}. Since an arbitrary number of events can be generated for simulation, and a larger number of events gives higher statistical precision, events in these datasets need to be reweighted to normalise their presence in a given region or category. To first order, the weight applied is
\begin{equation}
    w_{\sigma} = \frac{ \sigma \intlumi }{ N \varepsilon }
    \label{eq:xs_weight}
\end{equation}
where $\sigma$ is the cross section of the process at the order it was generated, \intlumi is the integrated luminosity of the \acrshort{lhc} data it is being compared to, $N$ is the number of events in the dataset before any analysis-level cuts are applied (or the sum of the generator weights), and $\varepsilon$ is the filter efficiency.


%=========================================================
