\section{Overview of the analysis}
\label{sec:htoinv_analysis_overview}

The analysis discussed in the remainder of the chapter is a dedicated search for invisibly decaying Higgs bosons in hadronic final states, incorporating all four of the production modes from the outset. In contrast to many of the previous analyses that separately set limits on $\BRof{\higgstoinv}$ by reinterpretation, our approach has many benefits. A simultaneous search for all of the production modes allows us to construct search regions to target each one, building in orthogonality to avoid overlap between them. Data and simulation samples, recipes for corrections and systematic uncertainties, the analysis framework, and results can all be shared to provide a cohesive and consistent environment from which to perform the analysis. As well as streamlining the process of the final combination over each production mechanism, communication when establishing the analysis ensures each can cover as much phase space as possible without the trouble of overlap or contamination.

Direct collaboration amongst several institutes divides up the task appropriately. Researchers at the University of Bristol, including as myself, and LLR (\emph{Laboratoire Leprince-Ringuet, \'{E}cole Polytechnique, Universit\'{e} Paris-Saclay}) focus on \ttH and the resolved \VH modes. Those at Imperial College London, who have a long history with the \acrshort{vbf} search~\cite{Chatrchyan:2014tja,Sirunyan:2018owy}, assume responsibility of this process. Researchers at Boston University---who have previously been involved in \acrshort{bsm} analyses with interpretations in invisibly decaying Higgs bosons~\cite{Khachatryan:2016mdm,Sirunyan:2017jix}---specialize in monojet and mono-\PVec searches. This translates into the boosted aspect of \VH, and \ggH modes of the analysis.

Emphasis will be placed on the non-VBF modes, particularly \ttH and resolved \VH as they are novel dedicated searches. The boosted \VH and \ggH mechanisms also under our charge, drawing on expertise from Boston. Accordingly, they will also be given some attention. Definitions of the physics objects used analysis-wide have already been discussed in Chpt.~\ref{sec:analysis_objects}. The data from \acrshort{cms} and from simulation, along with required corrections and systematic uncertainties, are acknowledged in Chpt.~\ref{sec:htoinv_data_sim}. These are followed by the event selection in Chpt.~\ref{sec:htoinv_event_selection}. Characterisation of the categorisation of production modes and phase space regions are illustrated in Chpts.~\ref{sec:htoinv_categorisation} and \ref{sec:region_definitions}, respectively. Methods for accurately estimating the background processes in the signal region are delineated in Chpt.~\ref{sec:htoinv_background_est}. The incorporation of these and the aforementioned sections in the statistical treatment are presented in Chpt.~\ref{sec:htoinv_satistical_treatment}, before the results of the analysis of the \ttH, \VH, and \ggH modes in Chpts.~\ref{sec:htoinv_analysis_ttH}, \ref{sec:htoinv_analysis_VH} and \ref{sec:htoinv_analysis_ggF}, respectively.

% Given the \acrshort{lhc} is a \emph{hadron} collider, processes with hadronic channels are the natural choices.\footnote{Or should I say ``most sensitive''?} \Gls{met} from the purely-invisible decay of the Higgs---and hadronic activity from the particles associated with the production mechanism---constitute the [final state], often known as a ``\text{\glspl{jet}} + \ptmiss$'' search.


%=========================================================


\section{Only tools and forces: software and toolkits}
\label{sec:htoinv_software}

The high energy physics community is well-acquainted with the software package \ROOT. The extensive suite of functions and tools it offers makes it the de facto standard in many analyses. Even though it is entrenched in particle physics, the native C\texttt{++} implementation and difficulty in integrating it with Python make \ROOT often cumbersome for newcomers to learn, and can be difficult to develop an analysis around it. In recent years, focus has started to shift toward industry-standard Python libraries such as \textsf{numpy} and \textsf{pandas} for analysis, and \textsf{matplotlib} or \textsf{seaborn} for plotting.

The FAST set of tools utilise these, along with vectorisation, to perform an analysis very quickly with simple YAML-controlled config files. Jobs can be submitted on the batch system at a given site, running the full analysis on the upwards of 15 billion events in as little as thirty minutes. Developed by colleagues at Bristol, a set of packages harmoniously work together to run most components of an analysis. Dataset information is gathered with \textsf{fast-curator} and stored in YAML configs. With \textsf{fast-carpenter}, modules (both custom and internal) for the different stages of the analysis process the datasets. Output is in the form of binned \textsf{pandas} dataframes of user-specified variables. They may be subsequently be fed into \textsf{fast-plotter} for visualisation as 1D histograms. All of the stages are controlled by YAML configs and are interpreted by \textsf{fast-flow}. Only a simple interface to \ROOT is required to extract the data. Further information on these packages are available at \url{http://fast-hep.web.cern.ch/fast-hep/}.

Before the main analysis is run with the above tools, a light skim---or reduction of events---of the remotely-available datasets is effectuated with \nanoAODtools.\footnote{See \url{https://github.com/cms-nanoAOD/nanoAOD-tools} for the original fork of the repository.} Operating on the nanoAOD data tier, the repository contains corrections, scale factors, and systematic uncertainties for \acrshort{cms} data and simulation. They are maintained by members of the Collaboration, so it is ensured they remain up to date. Our custom modules are applied on top of this: introducing additional scale factors and systematic uncertainties, classification of some physics objects, and add supplementary variables. Running over the datasets on the Worldwide LHC Computing Grid, output is stored on networked university storage elements. The primary benefit of this is a quicker input-output stream that improves the performance of the later stages of the analysis.\footnote{Link to our HToInv-nanoAOD-tools and chip repos? Would have to say they're restricted.}\footnote{Also not sure if I need to mention the later steps---\textsf{fast-datacard}, and Combine for the fit. Perhaps in the statistical treatment section?}
