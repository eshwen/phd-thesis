\section{Overview of the analysis}
\label{sec:htoinv_analysis_overview}

The analysis discussed in the remainder of the chapter is a dedicated search for invisibly decaying Higgs bosons in hadronic final states, incorporating three of the four main production modes. A combination with the \acrshort{vbf} analysis is also presented. In contrast to many of the previous analyses that separately set limits on $\BRof{\higgstoinv}$ by reinterpretation, this approach has many benefits. A simultaneous search for all of the production modes allows us to construct search regions to target each one, building in orthogonality to avoid overlap between them. Data and simulation samples, recipes for corrections and systematic uncertainties, the analysis framework, and results can all be shared to provide a cohesive and consistent environment from which to perform the analysis. As well as streamlining the process of the final combination over each production mechanism, communication when establishing the analysis ensures each can cover as much phase space as possible without the trouble of overlap or contamination.

Direct collaboration between the University of Bristol and Imperial College London divides up the task of analysing the various Higgs boson production modes appropriately. This thesis focuses on \ttH, \VH and \ggH mechanisms. Those at Imperial College London, who have a long history with the \acrshort{vbf} search~\cite{Chatrchyan:2014tja,Sirunyan:2018owy}, assume responsibility of this process. Results are shared between the two to achieve a fully combined limit on $\BRof{\higgstoinv}$.


%=========================================================

\subsection{Analysis strategy}
\label{subsec:htoinv_analysis_strategy}

Emphasis is placed on \ttH and \VH as they are novel dedicated searches. The \ggH mechanism also under our charge, and accordingly will be given attention. Given the \acrshort{lhc} is a \emph{hadron} collider, hadronic final states are naturally chosen for this analysis. \Gls{met} from the purely-invisible decay of the Higgs---and hadronic activity from the particles associated with the production mechanism---constitute the final state, often known as a ``\text{\glspl{jet}} $+$ \ptmiss'' search. In lieu of this, the dominant background processes from the \acrlong{sm} include \acrshort{qcd} with high \gls{jet} multiplicity, invisible decays of the \PZ boson, and those where the leptons in a decay are ``lost'' (\lostlepton) from misidentification or are outside the bounds of the detector acceptance. The latter is predominantly populated by \ttbar and leptonically decaying \PW bosons. To accurately estimate their presence in the signal region of the analysis, dedicated methods are employed. \Glspl{CR} enriched in leptons predict the lost lepton and \ztonunu processes. Sidebands to the signal region, where one or two selections otherwise designed to reject \acrshort{qcd} multijet events, are inverted to construct phase spaces populated in them.

Definitions of the physics objects used analysis-wide have already been discussed in Chpt.~\ref{sec:analysis_objects}. The data from \acrshort{cms} and from simulation are acknowledged in Chpt.~\ref{sec:htoinv_data_sim}. These are followed by the event selection in Chpt.~\ref{sec:htoinv_event_selection}. Characterisation of the categorisation of production modes and phase space regions are illustrated in Chpts.~\ref{sec:htoinv_categorisation} and \ref{sec:region_definitions}, respectively. Background estimation methods are delineated in Chpt.~\ref{sec:htoinv_background_est}. The incorporation of these and the aforementioned sections in the statistical treatment are presented in Chpt.~\ref{sec:htoinv_satistical_treatment}, before the results of the analysis of the \ttH, \VH, and \ggH modes in Chpts.~\ref{sec:htoinv_analysis_ttH}, \ref{sec:htoinv_analysis_VH} and \ref{sec:htoinv_analysis_ggF}, respectively.

Results from the combination of all of the production modes, including the \acrshort{vbf} analysis, close the chapter in Chpt.~\ref{sec:htoinv_combined_results}. Interpretations in simplified dark matter scenarios are also provided.


%=========================================================


\section{Only tools and forces: software and toolkits}
\label{sec:htoinv_software}

The high energy physics community is well-acquainted with the software package \ROOT. The extensive suite of functions and tools it offers makes it the de facto standard in many analyses. Even though it is entrenched in particle physics, the native C\texttt{++} implementation and difficulty in integrating it with Python make \ROOT often cumbersome for newcomers to learn, and can be difficult to develop an analysis around it. In recent years, focus has started to shift toward industry-standard Python libraries such as \textsf{numpy} and \textsf{pandas} for analysis, and \textsf{matplotlib} or \textsf{seaborn} for plotting.

The FAST set of tools utilise these, along with vectorisation, to perform an analysis very quickly with simple YAML-controlled config files. Jobs can be submitted on the batch system at a given site, running the full analysis on the upwards of 15 billion events in as little as thirty minutes. Developed by colleagues at Bristol, a set of packages harmoniously work together to run most components of an analysis. Dataset information is gathered with \textsf{fast-curator} and stored in YAML configs. With \textsf{fast-carpenter}, modules (both custom and internal) for the different stages of the analysis process the datasets. Output is in the form of binned \textsf{pandas} dataframes of user-specified variables. They may be subsequently be fed into \textsf{fast-plotter} for visualisation as 1D histograms. All of the stages are controlled by YAML configs and are interpreted by \textsf{fast-flow}. Only a simple interface to \ROOT is required to extract the data. Further information on these packages are available at \url{http://fast-hep.web.cern.ch/fast-hep/}.

Before the main analysis is run with the above tools, a light skim---or reduction of events---of the remotely-available datasets is effectuated with \nanoAODtools.\footnote{See \url{https://github.com/cms-nanoAOD/nanoAOD-tools} for the original fork of the repository.} Operating on the nanoAOD data tier, the repository contains corrections, scale factors, and systematic uncertainties for \acrshort{cms} data and simulation. They are maintained by members of the Collaboration, so it is ensured they remain up to date. Our custom modules are applied on top of this: introducing additional scale factors and systematic uncertainties, classification of some physics objects, and add supplementary variables. Running over the datasets on the Worldwide LHC Computing Grid, output is stored on networked university storage elements. The primary benefit of this is a quicker input-output stream that improves the performance of the later stages of the analysis.
