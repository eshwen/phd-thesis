\section{Overview of the analysis}
\label{sec:htoinv_analysis_overview}

The analysis discussed in the remainder of the chapter is a dedicated search for invisibly decaying Higgs bosons in hadronic final states, incorporating the \ttH and \VH production channels. In contrast to many of the previous analyses that separately set limits on $\BRof{\higgstoinv}$ by reinterpretation, this approach has many benefits. A simultaneous search for several production modes allows the construction of search regions to target each one, embedding orthogonality to avoid overlap between them. Data and simulation samples, recipes for corrections and systematic uncertainties, the analysis framework, and results can all be shared to provide a cohesive and consistent environment from which to perform the analysis. As well as streamlining the process of the final combination over each production mechanism, communication when establishing the analysis ensures each can cover as much phase space as possible without the trouble of overlap or contamination.

This analysis was performed in collaboration with \acrshort{cms}, specifically by researchers from the University of Bristol, Laboratoire Leprince-Ringuet, Imperial College London, and Boston University.


%=========================================================


\subsection{Analysis strategy}
\label{subsec:htoinv_analysis_strategy}

The analysis targets the \ttH and \VH channels as they are novel, dedicated searches. With expertise from previous hadronic \acrshort{bsm} searches and leptonic \higgstoinv searches already underway at \acrshort{cms}, hadronic final states are chosen for this analysis. Missing transverse momentum from the purely-invisible decay of the Higgs---and hadronic activity from the particles associated with the production mechanism---constitute the final state, often known as a ``\text{\glspl{jet}} $+$ \ptvecmiss'' search. In lieu of this, the dominant background processes from the \acrlong{sm} include \acrshort{qcd} with high \gls{jet} multiplicity, invisible decays of the \PZ boson, and those where the leptons from the decay are ``lost'' (\lostlepton) from misidentification or are outside the bounds of the detector acceptance. The latter is predominantly populated by \ttbar and leptonically decaying \PW bosons. To accurately estimate their presence in the signal region of the analysis, dedicated methods are employed. \Glspl{CR} separated by lepton and photon requirements predict the lost lepton and \ztonunu processes. Sidebands to the signal region, where one or more selections otherwise designed to reject \acrshort{qcd} multijet events are inverted, give rise to phase spaces enriched in them. A data-driven approach utilises these to predict the multijet background in the signal region.

Definitions of the physics objects used analysis-wide have already been discussed in Chpt.~\ref{sec:analysis_objects}. An outline of the contents of this chapter is as follows. A brief summary of the software packages appears in Chpt.~\ref{sec:htoinv_software}. The data from \acrshort{cms} and from simulation are then reported in Chpt.~\ref{sec:htoinv_data_sim}. Application of the event selection---described in Chpt.~\ref{sec:htoinv_event_selection}---is intended to separate signal from background and discard poorly measured events. Many cuts are universal, though some are category- or region-specific to mitigate problems found only there, or to further distinguish signal and background. Categorisation of the remaining events to highlight the production modes is next illustrated in Chpt.~\ref{sec:htoinv_categorisation}. The binning scheme and definition of the signal region are also included.

To extract an upper limit on $\BRof{\higgstoinv}$ in the absence of an excess in data, a fit of the signal and background to data is performed with the \CLs method~\cite{Read_2002}. A description of the model is given in Chpt.~\ref{sec:htoinv_satistical_treatment}. Estimation of the dominant background processes using the aforementioned \glspl{CR} and \glspl{SB} are described in Chpt.~\ref{sec:htoinv_background_estimation}. Corrections to simulation, designed to model the data more accurately, and associated systematic uncertainties are discussed in Chpt.~\ref{sec:htoinv_mc_corrections}. The culmination of all of the previous sections is in the presentation of the results in Chpt.~\ref{sec:htoinv_results}. Upper limits are provided for the \ttH- and \VH-targeting categories, and for the combination over the full Run-2 dataset. Interpretations of the results of the analysis in simplified dark matter scenarios close the chapter in Chpt.~\ref{sec:htoinv_dark_matter_models}.


%=========================================================


\section{Only tools and forces: software and toolkits}
\label{sec:htoinv_software}

Analysing high energy physics data is a long and complex task with many stages that must be stitched together. In this analysis, the first step involves a light skim---or reduction of events---of the remotely-available datasets, and is effectuated with \nanoAODtools.\footnote{See \url{https://github.com/cms-nanoAOD/nanoAOD-tools} for the original fork of the repository.} Operating on the nanoAOD data tier, the repository contains centrally-maintained corrections and systematic uncertainties related to physics objects. Custom modules are applied on top. Processing the datasets on the Worldwide LHC Computing Grid, output is stored on networked university storage elements for improved performance of the later stages of the analysis.

Skimmed data is analysed predominantly using the FAST set of tools~\cite{fast_hep_epj}, developed by colleagues at the University of Bristol. A suite of packages harmoniously work together to run most components of an analysis. The event selection and categorisation, as well as many studies and measurements of the data are conducted at this stage. Use of vectorisation and industry-standard Python libraries such as \textsf{numpy} and \textsf{pandas} allow complex and efficient processing with simple syntax. Visualisation can also be achieved with interfaces to \textsf{matplotlib}.

Output from the previous stage is processed through the fit of signal and background to data. Specification of all aspects are handled with the \textsf{HiggsAnalysis-CombinedLimit} package.\footnote{Official documentation: \url{https://cms-analysis.github.io/HiggsAnalysis-CombinedLimit/}.} A plethora of diagnostic information is available for understanding the effects of systematic uncertainties and other aspects of the analysis on the results.
